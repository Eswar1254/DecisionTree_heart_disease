# -*- coding: utf-8 -*-
"""heart.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zSw386Yoh5dP8yMU0HvZ5quyRvkGvN9r
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score,classification_report
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import cross_val_score, KFold, GridSearchCV
from sklearn.feature_selection import SelectKBest, chi2

#step1 =load model
#step2=missing values handleing
#step3=divide in z and y (indepent and dependent values)
#step4=train-test split
#step5=standardscaling xtrain and xtest

data=pd.read_csv('heart_disease.csv')

data

data.info()

data_isnull = data.isnull()

print(data_isnull.sum())

print(data.shape)

data.dropna(inplace=True)
print(data.isnull().sum())
print(data.shape)

data



convert={"sex":{"Female":0,"Male":1}}

data=data.replace(convert)

data

from sklearn.preprocessing import LabelEncoder
encoder=LabelEncoder()

data["sex"]=encoder.fit_transform(data["sex"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))

play_te

data

data["dataset"]=encoder.fit_transform(data["dataset"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data

data["id"]=encoder.fit_transform(data["id"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["cp"]=encoder.fit_transform(data["cp"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["trestbps"]=encoder.fit_transform(data["trestbps"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["chol"]=encoder.fit_transform(data["chol"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["fbs"]=encoder.fit_transform(data["fbs"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["restecg"]=encoder.fit_transform(data["restecg"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data

data["thalch"]=encoder.fit_transform(data["thalch"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["exang"]=encoder.fit_transform(data["exang"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["oldpeak"]=encoder.fit_transform(data["oldpeak"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["slope"]=encoder.fit_transform(data["slope"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["ca"]=encoder.fit_transform(data["ca"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data

data["thal"]=encoder.fit_transform(data["thal"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data["num"]=encoder.fit_transform(data["num"])
play_te=dict(zip(encoder.transform(encoder.classes_),encoder.classes_))
play_te

data

x=data.drop('num',axis=1)
y=data['num']

model=DecisionTreeClassifier()

model.fit(x,y)

# Access  the tree attributes
tree_=model.tree_
root_node =0  # as root node with index will be 0
feature_names = x.columns
# to get the feature indecx of the root node'
root_feature_index = tree_.feature[root_node]
# to get feature name from the original value
root_feature_name=feature_names[root_feature_index]

print("Index is", root_feature_index)
print("Feature Name is",root_feature_name)
print("Root Node Impurity is ",tree_.impurity[root_node])

# visualize decision trees
from sklearn import tree
import matplotlib.pyplot as plt
plt.figure(figsize=(36,12))
tree.plot_tree(model,feature_names=x.columns,filled=True,rounded=True)
plt.show()

from sklearn.preprocessing import StandardScaler
Scaler = StandardScaler()

from sklearn.model_selection import train_test_split

x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=42)

x_train_scaled = Scaler.fit_transform(x_train)
x_test_scaled = Scaler.fit_transform(x_test)

model = RandomForestClassifier()

from sklearn.model_selection import cross_val_score, KFold, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, chi2

k=5
kf = KFold(n_splits = k, shuffle = True, random_state = 42)
param_grid = {'n_estimators':[100,200,300],'max_depth':[5,7,9],'min_samples_split':[2,5,10],
              'max_features':['sqrt','log2']}

grid_search = GridSearchCV(estimator = model,
                          param_grid = param_grid,
                          cv = kf,n_jobs=-1,
                          verbose = 4,scoring = 'accuracy')
grid_search.fit(x_train_scaled,y_train)

print('Best Max_Depth:',grid_search.best_params_)
print('Best Accuracy:',grid_search.best_score_)

